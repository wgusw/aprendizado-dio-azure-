Aprendizado: Ambiente de Pipeline no Azure
Neste estudo, explorei os principais componentes de um pipeline no Azure Data Factory, entendendo como eles se conectam para mover e transformar dados de forma automatizada e escal√°vel.

üîß Conceitos Aprendidos
Linked Services: S√£o as conex√µes com fontes e destinos de dados, como Azure Blob Storage, bancos SQL, etc. Funcionam como ‚Äúpontes‚Äù entre o Data Factory e os dados externos.

Dataset: Representa os dados que ser√£o utilizados no pipeline. Ele define a estrutura e o caminho at√© os arquivos ou tabelas.

Integration Runtime (IR): √â o motor de execu√ß√£o das atividades do pipeline. Pode ser auto-hospedado ou na nuvem, e define onde e como os dados ser√£o processados.

Arquivos: Trabalhei principalmente com arquivos CSV armazenados no Azure Blob Storage, entendendo como fazer ingest√£o, transforma√ß√£o e movimenta√ß√£o desses dados dentro d
